# День 2: Классические алгоритмы машинного обучения

## Расписание дня

| Время | Активность |
|-------|------------|
| 09:00 - 10:30 | Теория: Линейные модели |
| 10:30 - 10:45 | Перерыв |
| 10:45 - 12:15 | Теория: Деревья решений и ансамблевые методы |
| 12:15 - 13:15 | Обед |
| 13:15 - 15:00 | Практика: Реализация и обучение моделей |
| 15:00 - 15:15 | Перерыв |
| 15:15 - 17:00 | Практика: Оценка и сравнение моделей |
| 17:00 - 18:00 | Работа над домашним заданием и вопросы |

## Теоретические материалы

### Линейные модели

#### Линейная регрессия
- Основные принципы и математическая формулировка
- Метод наименьших квадратов
- Регуляризация: Ridge (L2), Lasso (L1) и ElasticNet
- Оценка качества: MSE, RMSE, MAE, R²
- Преимущества и ограничения линейной регрессии

#### Логистическая регрессия
- Основные принципы и математическая формулировка
- Функция логистической активации (сигмоида)
- Метод максимального правдоподобия
- Регуляризация в логистической регрессии
- Многоклассовая классификация: one-vs-rest и softmax
- Оценка качества: accuracy, precision, recall, F1-score, ROC-AUC
- Преимущества и ограничения логистической регрессии

### Деревья решений и ансамблевые методы

#### Деревья решений
- Принцип работы деревьев решений
- Критерии разбиения: энтропия, индекс Джини
- Алгоритмы построения деревьев: ID3, C4.5, CART
- Преимущества и недостатки деревьев решений
- Визуализация и интерпретация деревьев

#### Ансамблевые методы
- Принципы ансамблирования моделей
- Бэггинг и случайный лес (Random Forest)
- Бустинг: AdaBoost, Gradient Boosting
- XGBoost, LightGBM, CatBoost: особенности и преимущества
- Стекинг моделей

### Метрики качества и оценка моделей

#### Метрики для задач классификации
- Матрица ошибок (confusion matrix)
- Точность (accuracy)
- Точность и полнота (precision and recall)
- F1-мера
- ROC-кривая и AUC
- Precision-Recall кривая
- Логарифмическая функция потерь (log loss)

#### Метрики для задач регрессии
- Среднеквадратическая ошибка (MSE)
- Корень из среднеквадратической ошибки (RMSE)
- Средняя абсолютная ошибка (MAE)
- Коэффициент детерминации (R²)
- Средняя абсолютная процентная ошибка (MAPE)

#### Кросс-валидация
- Принципы кросс-валидации
- K-fold кросс-валидация
- Стратифицированная кросс-валидация
- Leave-one-out кросс-валидация
- Временная кросс-валидация для временных рядов

## Практические задания

### Задание 1: Реализация и обучение линейных моделей

#### Подготовка данных
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Загрузка данных (например, Boston Housing dataset)
from sklearn.datasets import load_boston
boston = load_boston()
X = boston.data
y = boston.target

# Разделение на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Масштабирование признаков
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

#### Линейная регрессия
```python
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score

# Обычная линейная регрессия
lr = LinearRegression()
lr.fit(X_train_scaled, y_train)
y_pred_lr = lr.predict(X_test_scaled)

# Ridge регрессия
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)
y_pred_ridge = ridge.predict(X_test_scaled)

# Lasso регрессия
lasso = Lasso(alpha=0.1)
lasso.fit(X_train_scaled, y_train)
y_pred_lasso = lasso.predict(X_test_scaled)

# ElasticNet регрессия
elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)
elastic.fit(X_train_scaled, y_train)
y_pred_elastic = elastic.predict(X_test_scaled)

# Оценка моделей
models = {
    'Linear Regression': y_pred_lr,
    'Ridge': y_pred_ridge,
    'Lasso': y_pred_lasso,
    'ElasticNet': y_pred_elastic
}

for name, y_pred in models.items():
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    print(f"{name}: MSE={mse:.4f}, RMSE={rmse:.4f}, R²={r2:.4f}")
```

#### Логистическая регрессия
```python
from sklearn.datasets import load_breast_cancer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

# Загрузка данных (например, Breast Cancer dataset)
cancer = load_breast_cancer()
X = cancer.data
y = cancer.target

# Разделение на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Масштабирование признаков
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Обучение логистической регрессии
logreg = LogisticRegression(C=1.0, solver='liblinear')
logreg.fit(X_train_scaled, y_train)
y_pred = logreg.predict(X_test_scaled)
y_prob = logreg.predict_proba(X_test_scaled)[:, 1]

# Оценка модели
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_prob)
conf_matrix = confusion_matrix(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"ROC AUC: {roc_auc:.4f}")
print("Confusion Matrix:")
print(conf_matrix)

# Визуализация ROC-кривой
from sklearn.metrics import roc_curve

fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()
```

### Задание 2: Построение и визуализация деревьев решений

```python
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.datasets import load_iris

# Загрузка данных (например, Iris dataset)
iris = load_iris()
X = iris.data
y = iris.target

# Разделение на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Обучение дерева решений
dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(X_train, y_train)
y_pred = dt.predict(X_test)

# Оценка модели
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

# Визуализация дерева решений
plt.figure(figsize=(15, 10))
plot_tree(dt, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)
plt.title("Decision Tree for Iris Dataset")
plt.show()

# Важность признаков
feature_importance = pd.DataFrame({
    'Feature': iris.feature_names,
    'Importance': dt.feature_importances_
}).sort_values('Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance)
plt.title('Feature Importance')
plt.tight_layout()
plt.show()
```

### Задание 3: Применение ансамблевых методов

```python
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.metrics import classification_report

# Загрузка данных (например, Wine dataset)
from sklearn.datasets import load_wine
wine = load_wine()
X = wine.data
y = wine.target

# Разделение на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Масштабирование признаков
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Обучение моделей
models = {
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42)
}

results = {}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    print(f"{name} Accuracy: {accuracy:.4f}")
    print(classification_report(y_test, y_pred, target_names=wine.target_names))
    print("-" * 50)

# Визуализация результатов
plt.figure(figsize=(10, 6))
sns.barplot(x=list(results.keys()), y=list(results.values()))
plt.title('Model Comparison')
plt.ylabel('Accuracy')
plt.ylim(0.8, 1.0)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

### Задание 4: Оценка и сравнение моделей с использованием кросс-валидации

```python
from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC

# Загрузка данных (например, Breast Cancer dataset)
cancer = load_breast_cancer()
X = cancer.data
y = cancer.target

# Масштабирование признаков
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Определение моделей для сравнения
models = {
    'Logistic Regression': LogisticRegression(random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'SVM': SVC(random_state=42)
}

# Настройка кросс-валидации
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Оценка моделей с помощью кросс-валидации
results = {}

for name, model in models.items():
    scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='accuracy')
    results[name] = scores
    print(f"{name}: Mean Accuracy = {scores.mean():.4f}, Std = {scores.std():.4f}")

# Визуализация результатов
plt.figure(figsize=(12, 6))
sns.boxplot(data=pd.DataFrame(results))
plt.title('Model Comparison with Cross-Validation')
plt.ylabel('Accuracy')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

## Домашнее задание

### Задание 1: Решение задачи классификации с использованием различных алгоритмов

Используя набор данных "Adult" (или другой предложенный набор):

1. Загрузите данные и выполните необходимую предобработку
2. Разделите данные на обучающую и тестовую выборки
3. Реализуйте и обучите следующие модели:
   - Логистическая регрессия
   - Дерево решений
   - Случайный лес
   - Градиентный бустинг
4. Для каждой модели:
   - Настройте гиперпараметры с помощью GridSearchCV или RandomizedSearchCV
   - Оцените качество модели на тестовой выборке с использованием различных метрик
   - Постройте ROC-кривую и вычислите AUC
5. Сравните результаты всех моделей и сделайте выводы

### Задание 2: Сравнительный анализ эффективности моделей

1. Выберите 3-4 различных набора данных для классификации или регрессии
2. Для каждого набора данных:
   - Выполните необходимую предобработку
   - Обучите 3-4 различные модели
   - Оцените качество моделей с помощью кросс-валидации
3. Проведите сравнительный анализ:
   - Какие модели показывают лучшие результаты на разных наборах данных?
   - Как влияют характеристики данных (размер выборки, количество признаков, баланс классов) на эффективность моделей?
   - Какие модели требуют больше времени на обучение и предсказание?
4. Подготовьте отчет с результатами анализа и визуализациями

## Ресурсы и материалы

### Основные ресурсы
- [Документация scikit-learn по линейным моделям](https://scikit-learn.org/stable/modules/linear_model.html)
- [Документация scikit-learn по деревьям решений](https://scikit-learn.org/stable/modules/tree.html)
- [Документация scikit-learn по ансамблевым методам](https://scikit-learn.org/stable/modules/ensemble.html)
- [Документация scikit-learn по метрикам качества](https://scikit-learn.org/stable/modules/model_evaluation.html)

### Дополнительные материалы
- [Статья "Understanding Random Forest"](https://towardsdatascience.com/understanding-random-forest-58381e0602d2)
- [Статья "A Comprehensive Guide to Gradient Boosting"](https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/)
- [Книга "The Elements of Statistical Learning"](https://web.stanford.edu/~hastie/ElemStatLearn/)
- [Курс "Machine Learning" от Andrew Ng на Coursera](https://www.coursera.org/learn/machine-learning)

### Наборы данных для практики
- [Adult Dataset](https://archive.ics.uci.edu/ml/datasets/adult)
- [Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality)
- [Heart Disease Dataset](https://www.kaggle.com/ronitf/heart-disease-uci)

