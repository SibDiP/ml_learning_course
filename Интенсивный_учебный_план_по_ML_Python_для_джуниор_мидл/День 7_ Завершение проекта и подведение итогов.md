# День 7: Завершение проекта и подведение итогов

## Расписание дня

| Время | Активность |
|-------|------------|
| 09:00 - 10:30 | Теория: Лучшие практики в ML-проектах |
| 10:30 - 10:45 | Перерыв |
| 10:45 - 12:15 | Теория: Подготовка проекта для портфолио и дальнейшие направления развития |
| 12:15 - 13:15 | Обед |
| 13:15 - 15:00 | Практика: Завершение работы над финальным проектом |
| 15:00 - 15:15 | Перерыв |
| 15:15 - 17:00 | Практика: Подготовка презентации проекта и документации |
| 17:00 - 18:00 | Подведение итогов курса и обсуждение дальнейших шагов |

## Теоретические материалы

### Лучшие практики в ML-проектах

#### Структурирование ML-проектов
- Организация кода и данных
- Модульный подход к разработке
- Управление версиями кода и данных
- Документирование кода и моделей
- Воспроизводимость экспериментов

#### Оценка и выбор моделей
- Правильное разделение данных
- Кросс-валидация и ее применение
- Выбор метрик в зависимости от задачи
- Интерпретация результатов
- Сравнение моделей и выбор лучшей

#### Оптимизация моделей
- Оптимизация гиперпараметров
- Ансамблирование моделей
- Дистилляция знаний
- Квантизация и прунинг
- Оптимизация для производственного использования

#### Обработка данных
- Обнаружение и обработка выбросов
- Работа с несбалансированными данными
- Обработка пропущенных значений
- Обработка категориальных признаков
- Масштабирование и нормализация

#### Мониторинг и обновление моделей
- Отслеживание производительности модели
- Обнаружение дрейфа данных
- Стратегии обновления моделей
- A/B тестирование моделей
- Обратная связь от пользователей

### Подготовка проекта для портфолио

#### Структура проекта для портфолио
- Четкое описание проблемы и решения
- Структурированный код и документация
- Визуализация результатов
- Демонстрация процесса разработки
- Выводы и возможные улучшения

#### Документирование проекта
- Написание качественного README
- Документирование кода и функций
- Создание руководства пользователя
- Описание архитектуры решения
- Документирование процесса разработки и экспериментов

#### Создание демонстрационных материалов
- Интерактивные демонстрации
- Визуализации и графики
- Примеры использования
- Видеодемонстрации
- Презентации проекта

#### Размещение проекта
- GitHub и GitLab
- Kaggle Kernels и соревнования
- Личный блог или сайт
- Платформы для демонстрации ML-проектов
- Социальные сети для разработчиков

### Дальнейшие направления развития в ML

#### Специализации в машинном обучении
- Компьютерное зрение
- Обработка естественного языка
- Рекомендательные системы
- Обработка временных рядов
- Обучение с подкреплением

#### Продвинутые темы для изучения
- Генеративные модели (GAN, VAE, диффузионные модели)
- Трансформеры и большие языковые модели
- Мультимодальное обучение
- Федеративное обучение
- Квантовое машинное обучение

#### Инструменты и платформы для развития
- Облачные платформы для ML (AWS, GCP, Azure)
- Специализированное оборудование (GPU, TPU)
- Фреймворки для продвинутых задач
- Инструменты для автоматизации ML (AutoML)
- Платформы для развертывания моделей

#### Карьерные пути в ML
- ML-инженер
- Исследователь в области ML
- Data Scientist
- MLOps-инженер
- Специалист по этике ИИ

#### Ресурсы для дальнейшего обучения
- Онлайн-курсы и специализации
- Книги и научные статьи
- Конференции и митапы
- Соревнования по ML
- Открытые проекты и сообщества

## Практические задания

### Задание 1: Завершение работы над финальным проектом

#### Доработка модели
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# Загрузка данных (пример)
# data = pd.read_csv('data/processed/features.csv')
# X = data.drop('target', axis=1)
# y = data['target']

# Разделение данных
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Создание модели (пример для классификации изображений)
def create_model(input_shape, num_classes):
    model = keras.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model

# Обучение модели
# model = create_model(input_shape=(32, 32, 3), num_classes=10)
# history = model.fit(
#     X_train, y_train,
#     epochs=20,
#     batch_size=64,
#     validation_split=0.2,
#     callbacks=[
#         keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)
#     ]
# )

# Оценка модели
# test_loss, test_acc = model.evaluate(X_test, y_test)
# print(f"Test accuracy: {test_acc:.4f}")

# Предсказания
# y_pred = model.predict(X_test)
# y_pred_classes = np.argmax(y_pred, axis=1)

# Отчет о классификации
# print(classification_report(y_test, y_pred_classes))

# Матрица ошибок
# cm = confusion_matrix(y_test, y_pred_classes)
# plt.figure(figsize=(10, 8))
# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
# plt.title('Confusion Matrix')
# plt.xlabel('Predicted Label')
# plt.ylabel('True Label')
# plt.show()

# Сохранение модели
# model.save('models/final_model.h5')
# print("Модель сохранена в models/final_model.h5")
```

#### Создание API для модели
```python
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
import tensorflow as tf
import numpy as np
import io
from PIL import Image
import uvicorn

# Создание FastAPI приложения
app = FastAPI(
    title="ML Model API",
    description="API для доступа к модели машинного обучения",
    version="1.0.0"
)

# Загрузка модели
# model = tf.keras.models.load_model('models/final_model.h5')

# Классы (пример для CIFAR-10)
# class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
#                'dog', 'frog', 'horse', 'ship', 'truck']

# Предобработка изображения
def preprocess_image(image_bytes):
    image = Image.open(io.BytesIO(image_bytes))
    image = image.resize((32, 32))  # Размер зависит от модели
    image = np.array(image) / 255.0
    return np.expand_dims(image, axis=0)

@app.get("/")
def read_root():
    return {"message": "ML Model API"}

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # Чтение файла
        contents = await file.read()
        
        # Предобработка изображения
        image = preprocess_image(contents)
        
        # Предсказание
        # predictions = model.predict(image)
        # predicted_class = np.argmax(predictions[0])
        # confidence = float(predictions[0][predicted_class])
        
        # Формирование ответа
        # response = {
        #     "class": class_names[predicted_class],
        #     "class_id": int(predicted_class),
        #     "confidence": confidence
        # }
        
        # Для примера
        response = {
            "class": "cat",
            "class_id": 3,
            "confidence": 0.95
        }
        
        return JSONResponse(content=response)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Запуск сервера
# if __name__ == "__main__":
#     uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=True)
```

#### Создание веб-интерфейса с использованием Streamlit
```python
import streamlit as st
import requests
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import io

# Настройка страницы
st.set_page_config(
    page_title="ML Model Demo",
    page_icon="🤖",
    layout="wide"
)

# Заголовок
st.title("Демонстрация модели машинного обучения")

# Боковая панель
st.sidebar.header("Настройки")
model_type = st.sidebar.selectbox(
    "Выберите тип модели",
    ["Классификация изображений", "Анализ тональности текста", "Прогнозирование временных рядов"]
)

# Основной контент
st.header(f"Модель: {model_type}")

if model_type == "Классификация изображений":
    st.write("Загрузите изображение для классификации:")
    
    uploaded_file = st.file_uploader("Выберите изображение...", type=["jpg", "jpeg", "png"])
    
    if uploaded_file is not None:
        # Отображение загруженного изображения
        image = Image.open(uploaded_file)
        st.image(image, caption="Загруженное изображение", width=300)
        
        # Кнопка для предсказания
        if st.button("Классифицировать"):
            # Подготовка файла для отправки
            files = {"file": uploaded_file.getvalue()}
            
            # Отправка запроса к API
            # response = requests.post("http://localhost:8000/predict", files=files)
            
            # Для примера
            # response_json = response.json()
            response_json = {
                "class": "cat",
                "class_id": 3,
                "confidence": 0.95
            }
            
            # Отображение результатов
            st.success(f"Класс: {response_json['class']}")
            st.info(f"Уверенность: {response_json['confidence']:.2%}")
            
            # Визуализация уверенности
            st.subheader("Уверенность модели")
            confidence = response_json['confidence']
            fig, ax = plt.subplots(figsize=(10, 2))
            ax.barh(["Уверенность"], [confidence], color="green")
            ax.barh(["Уверенность"], [1-confidence], left=[confidence], color="red")
            ax.set_xlim(0, 1)
            ax.set_xticks([0, 0.25, 0.5, 0.75, 1.0])
            ax.set_xticklabels(["0%", "25%", "50%", "75%", "100%"])
            st.pyplot(fig)

elif model_type == "Анализ тональности текста":
    st.write("Введите текст для анализа тональности:")
    
    text = st.text_area("Текст", height=150)
    
    if st.button("Анализировать") and text:
        # Для примера
        sentiment = "Положительный"
        confidence = 0.85
        
        # Отображение результатов
        st.success(f"Тональность: {sentiment}")
        st.info(f"Уверенность: {confidence:.2%}")
        
        # Визуализация уверенности
        st.subheader("Уверенность модели")
        fig, ax = plt.subplots(figsize=(10, 2))
        ax.barh(["Уверенность"], [confidence], color="green")
        ax.barh(["Уверенность"], [1-confidence], left=[confidence], color="red")
        ax.set_xlim(0, 1)
        ax.set_xticks([0, 0.25, 0.5, 0.75, 1.0])
        ax.set_xticklabels(["0%", "25%", "50%", "75%", "100%"])
        st.pyplot(fig)

elif model_type == "Прогнозирование временных рядов":
    st.write("Загрузите данные временного ряда (CSV):")
    
    uploaded_file = st.file_uploader("Выберите CSV файл...", type=["csv"])
    
    if uploaded_file is not None:
        # Загрузка данных
        data = pd.read_csv(uploaded_file)
        st.write("Предварительный просмотр данных:")
        st.dataframe(data.head())
        
        # Выбор столбцов
        time_col = st.selectbox("Выберите столбец времени", data.columns)
        value_col = st.selectbox("Выберите столбец значений", data.columns)
        
        # Визуализация данных
        st.subheader("Визуализация временного ряда")
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.plot(data[time_col], data[value_col])
        ax.set_xlabel(time_col)
        ax.set_ylabel(value_col)
        ax.grid(True)
        st.pyplot(fig)
        
        # Прогнозирование
        if st.button("Прогнозировать"):
            # Для примера
            forecast_periods = 10
            forecast = np.random.normal(data[value_col].mean(), data[value_col].std(), forecast_periods)
            
            # Визуализация прогноза
            st.subheader("Прогноз")
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(data[time_col], data[value_col], label="Исторические данные")
            
            # Создание новых меток времени для прогноза
            last_date = pd.to_datetime(data[time_col].iloc[-1])
            forecast_dates = pd.date_range(start=last_date, periods=forecast_periods+1)[1:]
            
            ax.plot(forecast_dates, forecast, label="Прогноз", color="red")
            ax.set_xlabel(time_col)
            ax.set_ylabel(value_col)
            ax.grid(True)
            ax.legend()
            st.pyplot(fig)

# Информация о проекте
st.sidebar.markdown("---")
st.sidebar.subheader("О проекте")
st.sidebar.info(
    "Этот демонстрационный интерфейс показывает возможности "
    "модели машинного обучения, разработанной в рамках "
    "интенсивного курса по ML Python."
)
st.sidebar.markdown("---")
st.sidebar.markdown("© 2025 ML Python Intensive")
```

### Задание 2: Подготовка презентации проекта и документации

#### Создание презентации проекта
```python
import os
from fpdf import FPDF

# Создание директории для презентации
os.makedirs("reports/presentation", exist_ok=True)

# Создание PDF презентации
pdf = FPDF()

# Титульная страница
pdf.add_page()
pdf.set_font("Arial", "B", 24)
pdf.cell(0, 20, "Проект машинного обучения", ln=True, align="C")
pdf.set_font("Arial", "", 16)
pdf.cell(0, 15, "Интенсивный курс по ML Python", ln=True, align="C")
pdf.cell(0, 10, "2025", ln=True, align="C")

# Страница с описанием проекта
pdf.add_page()
pdf.set_font("Arial", "B", 18)
pdf.cell(0, 15, "Описание проекта", ln=True)
pdf.set_font("Arial", "", 12)
pdf.multi_cell(0, 10, "Этот проект демонстрирует применение методов машинного обучения для решения задачи классификации изображений. В рамках проекта была разработана и обучена сверточная нейронная сеть, способная классифицировать изображения с высокой точностью.")
pdf.ln(5)
pdf.multi_cell(0, 10, "Проект включает в себя полный цикл разработки: от подготовки данных до развертывания модели в виде API и веб-интерфейса.")

# Страница с описанием данных
pdf.add_page()
pdf.set_font("Arial", "B", 18)
pdf.cell(0, 15, "Данные", ln=True)
pdf.set_font("Arial", "", 12)
pdf.multi_cell(0, 10, "Для обучения модели использовался набор данных CIFAR-10, содержащий 60000 цветных изображений размером 32x32 пикселя, разделенных на 10 классов.")
pdf.ln(5)
pdf.multi_cell(0, 10, "Классы: самолет, автомобиль, птица, кошка, олень, собака, лягушка, лошадь, корабль, грузовик.")
pdf.ln(5)
pdf.multi_cell(0, 10, "Данные были разделены на обучающую (80%) и тестовую (20%) выборки. Для валидации во время обучения использовалось 20% обучающей выборки.")

# Страница с описанием модели
pdf.add_page()
pdf.set_font("Arial", "B", 18)
pdf.cell(0, 15, "Модель", ln=True)
pdf.set_font("Arial", "", 12)
pdf.multi_cell(0, 10, "Для решения задачи была разработана сверточная нейронная сеть (CNN) со следующей архитектурой:")
pdf.ln(5)
pdf.multi_cell(0, 10, "1. Сверточный слой (32 фильтра, размер ядра 3x3, активация ReLU)\n2. Слой подвыборки (MaxPooling, размер пула 2x2)\n3. Сверточный слой (64 фильтра, размер ядра 3x3, активация ReLU)\n4. Слой подвыборки (MaxPooling, размер пула 2x2)\n5. Сверточный слой (128 фильтров, размер ядра 3x3, активация ReLU)\n6. Слой подвыборки (MaxPooling, размер пула 2x2)\n7. Полносвязный слой (128 нейронов, активация ReLU)\n8. Dropout (вероятность 0.5)\n9. Выходной слой (10 нейронов, активация softmax)")

# Страница с результатами
pdf.add_page()
pdf.set_font("Arial", "B", 18)
pdf.cell(0, 15, "Результаты", ln=True)
pdf.set_font("Arial", "", 12)
pdf.multi_cell(0, 10, "Модель была обучена на протяжении 20 эпох с использованием оптимизатора Adam и функции потерь categorical_crossentropy.")
pdf.ln(5)
pdf.multi_cell(0, 10, "Результаты на тестовой выборке:")
pdf.ln(5)
pdf.multi_cell(0, 10, "- Точность (Accuracy): 85%\n- Precision: 84%\n- Recall: 83%\n- F1-score: 83%")

# Страница с выводами
pdf.add_page()
pdf.set_font("Arial", "B", 18)
pdf.cell(0, 15, "Выводы и дальнейшие шаги", ln=True)
pdf.set_font("Arial", "", 12)
pdf.multi_cell(0, 10, "Разработанная модель демонстрирует хорошую точность классификации изображений. Для дальнейшего улучшения результатов можно рассмотреть следующие направления:")
pdf.ln(5)
pdf.multi_cell(0, 10, "1. Использование более глубоких архитектур (ResNet, EfficientNet)\n2. Применение трансферного обучения\n3. Расширение набора данных и аугментация\n4. Оптимизация гиперпараметров\n5. Ансамблирование моделей")

# Сохранение PDF
pdf.output("reports/presentation/project_presentation.pdf")

print("Презентация создана: reports/presentation/project_presentation.pdf")
```

#### Создание документации проекта
```python
# Создание README.md
with open("README.md", "w") as f:
    f.write("""# Проект по классификации изображений

## Описание проекта

Этот проект демонстрирует применение методов машинного обучения для решения задачи классификации изображений. В рамках проекта была разработана и обучена сверточная нейронная сеть, способная классифицировать изображения с высокой точностью.

Проект включает в себя полный цикл разработки: от подготовки данных до развертывания модели в виде API и веб-интерфейса.

## Структура проекта

```
├── data
│   ├── processed      # Обработанные данные
│   └── raw            # Исходные данные
├── models             # Обученные модели
├── notebooks          # Jupyter notebooks
├── reports            # Отчеты и визуализации
│   ├── figures        # Графики и диаграммы
│   └── presentation   # Презентация проекта
└── src                # Исходный код
    ├── data           # Скрипты для загрузки и обработки данных
    ├── features       # Скрипты для создания признаков
    ├── models         # Скрипты для обучения и оценки моделей
    └── visualization  # Скрипты для визуализации
```

## Данные

Для обучения модели использовался набор данных CIFAR-10, содержащий 60000 цветных изображений размером 32x32 пикселя, разделенных на 10 классов:

- Самолет
- Автомобиль
- Птица
- Кошка
- Олень
- Собака
- Лягушка
- Лошадь
- Корабль
- Грузовик

## Модель

Для решения задачи была разработана сверточная нейронная сеть (CNN) со следующей архитектурой:

1. Сверточный слой (32 фильтра, размер ядра 3x3, активация ReLU)
2. Слой подвыборки (MaxPooling, размер пула 2x2)
3. Сверточный слой (64 фильтра, размер ядра 3x3, активация ReLU)
4. Слой подвыборки (MaxPooling, размер пула 2x2)
5. Сверточный слой (128 фильтров, размер ядра 3x3, активация ReLU)
6. Слой подвыборки (MaxPooling, размер пула 2x2)
7. Полносвязный слой (128 нейронов, активация ReLU)
8. Dropout (вероятность 0.5)
9. Выходной слой (10 нейронов, активация softmax)

## Результаты

Модель была обучена на протяжении 20 эпох с использованием оптимизатора Adam и функции потерь categorical_crossentropy.

Результаты на тестовой выборке:
- Точность (Accuracy): 85%
- Precision: 84%
- Recall: 83%
- F1-score: 83%

## Установка и использование

### Установка зависимостей

```bash
pip install -r requirements.txt
```

### Обучение модели

```bash
python src/models/train_model.py
```

### Запуск API

```bash
python src/app.py
```

### Запуск веб-интерфейса

```bash
streamlit run src/streamlit_app.py
```

## API

API предоставляет следующие эндпоинты:

- `GET /`: Информация о API
- `POST /predict`: Классификация изображения
  - Параметры: файл изображения
  - Возвращает: класс, идентификатор класса и уверенность

## Веб-интерфейс

Веб-интерфейс позволяет:
- Загружать изображения для классификации
- Просматривать результаты классификации
- Визуализировать уверенность модели

## Автор

Проект разработан в рамках интенсивного курса по ML Python.

## Лицензия

MIT
""")

print("Документация проекта создана: README.md")
```

## Домашнее задание

### Задание: Финализация проекта и подготовка всех материалов

1. Завершите работу над финальным проектом:
   - Доработайте модель до финальной версии
   - Оптимизируйте гиперпараметры
   - Проведите финальную оценку модели на тестовой выборке
   - Сохраните обученную модель и все необходимые артефакты

2. Подготовьте документацию проекта:
   - Создайте подробный README.md с описанием проекта, инструкциями по установке и использованию
   - Документируйте код с помощью docstrings и комментариев
   - Создайте руководство пользователя для API и веб-интерфейса
   - Опишите архитектуру решения и принятые решения

3. Подготовьте презентацию проекта:
   - Создайте слайды с описанием проблемы, решения и результатов
   - Подготовьте демонстрацию работы модели
   - Включите визуализации и графики для иллюстрации результатов
   - Подготовьте краткое выступление на 5-10 минут

4. Упакуйте проект для развертывания:
   - Создайте Docker-контейнер для API
   - Подготовьте инструкции по развертыванию
   - Убедитесь, что все зависимости указаны в requirements.txt
   - Проверьте работоспособность всех компонентов

5. Подготовьте проект для портфолио:
   - Загрузите код на GitHub
   - Создайте демонстрационное видео работы проекта
   - Напишите статью или пост о проекте
   - Подготовьте краткое описание проекта для резюме

## Ресурсы и материалы

### Основные ресурсы
- [Документация Docker](https://docs.docker.com/)
- [Документация FastAPI](https://fastapi.tiangolo.com/)
- [Документация Streamlit](https://docs.streamlit.io/)
- [Руководство по GitHub](https://docs.github.com/en)
- [Руководство по созданию презентаций](https://www.canva.com/learn/how-to-create-a-presentation/)

### Дополнительные материалы
- [Книга "Building Machine Learning Powered Applications" by Emmanuel Ameisen](https://www.oreilly.com/library/view/building-machine-learning/9781492045106/)
- [Статья "How to Build a Data Science Portfolio"](https://towardsdatascience.com/how-to-build-a-data-science-portfolio-5f566517c79c)
- [Курс "Machine Learning Engineering for Production (MLOps)" на Coursera](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops)
- [Статья "Deploying Machine Learning Models: A Checklist"](https://ml-ops.org/content/mlops-principles)
- [Руководство "How to Document Machine Learning Projects"](https://towardsdatascience.com/how-to-document-machine-learning-projects-c4f3f94fc1b1)

### Платформы для размещения проектов
- [GitHub](https://github.com/)
- [Kaggle](https://www.kaggle.com/)
- [Hugging Face](https://huggingface.co/)
- [Streamlit Sharing](https://streamlit.io/sharing)
- [Heroku](https://www.heroku.com/)

### Ресурсы для дальнейшего обучения
- [Kaggle Competitions](https://www.kaggle.com/competitions)
- [Papers with Code](https://paperswithcode.com/)
- [arXiv](https://arxiv.org/)
- [ML Conferences](https://www.guide2research.com/conferences/machine-learning)
- [ML YouTube Channels](https://www.youtube.com/c/3blue1brown)

