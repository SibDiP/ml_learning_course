# День 1: Основы машинного обучения и подготовка данных

## Расписание дня

| Время         | Активность                                                |
| ------------- | --------------------------------------------------------- |
| 09:00 - 10:30 | Теория: Введение в машинное обучение                      |
| 10:30 - 10:45 | Перерыв                                                   |
| 10:45 - 12:15 | Теория: Жизненный цикл ML-проекта и предобработка данных  |
| 12:15 - 13:15 | Обед                                                      |
| 13:15 - 15:00 | Практика: Настройка окружения и разведочный анализ данных |
| 15:00 - 15:15 | Перерыв                                                   |
| 15:15 - 17:00 | Практика: Предобработка данных и визуализация             |
| 17:00 - 18:00 | Работа над домашним заданием и вопросы                    |

## Теоретические материалы

### Введение в машинное обучение

#### Основные понятия и определения
- [[Что такое машинное обучение]]
- [[Отличия от традиционного программирования]]
- [[Основные парадигмы машинного обучения]]:
  - Обучеие с учителем (Supervised Learning)
  - Обучение без учителя (Unsupнervised Learning)
  - Обучение с подкреплением (Reinforcement Learning)

#### [[Типы задач машинного обучения]]
- Классификация
- Регрессия
- Кластеризация
- Снижение размерности
- Обнаружение аномалий
- Генерация данных

#### [[Основные концепции]]
- Признаки (features) и целевые переменные (target variables)
- Обучающая, валидационная и тестовая выборки
- Переобучение (overfitting) и недообучение (underfitting)
- Компромисс между смещением и дисперсией (bias-variance tradeoff)

### Жизненный цикл ML-проекта

#### [[Этапы ML-проекта]]
1. Определение проблемы и целей
2. Сбор и подготовка данных
3. Разведочный анализ данных (EDA)
4. Предобработка данных
5. Выбор и обучение модели
6. Оценка и оптимизация модели
7. Развертывание и мониторинг

#### [[Методы предобработки данных]]
- Обработка пропущенных значений
- Обработка выбросов
- Нормализация и стандартизация
- Кодирование категориальных признаков
- Балансировка классов
- Создание новых признаков (feature engineering)

#### [[Разведочный анализ данных (EDA)]]
- Цели и задачи EDA
- Статистический анализ данных
- Визуализация распределений
- Анализ корреляций
- Выявление паттернов и зависимостей

---

## Дополнительная информация

[[".mean(), .median(), mode()"]]
[[Pandas DataFrame, View, Series]]
## Практические задания

### Задание 1: Настройка рабочего окружения

#### Установка необходимых библиотек
```python
# Установка библиотек
!pip install numpy pandas matplotlib seaborn scikit-learn jupyter

# Проверка версий
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import __version__ as sklearn_version

print(f"NumPy version: {np.__version__}")
print(f"Pandas version: {pd.__version__}")
print(f"Scikit-learn version: {sklearn_version}")
```

#### Настройка Jupyter Notebook
- Создание нового проекта
- Настройка автодополнения и подсветки синтаксиса
- Полезные расширения для Jupyter

### Задание 2: Разведочный анализ данных

#### Загрузка и первичный анализ набора данных
```python
# Загрузка данных
df = pd.read_csv('housing.csv')

# Просмотр первых строк
print(df.head())

# Информация о структуре данных
print(df.info())

# Статистическое описание
print(df.describe())

# Проверка пропущенных значений
print(df.isnull().sum())
```

#### [[Визуализация данных]]
```python
# Настройка стиля
plt.style.use('seaborn-whitegrid')
sns.set(font_scale=1.2)

# Гистограммы числовых признаков
fig, axes = plt.subplots(3, 3, figsize=(15, 12))
axes = axes.flatten()

numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns

for i, col in enumerate(numeric_cols[:9]):
    sns.histplot(df[col], kde=True, ax=axes[i])
    axes[i].set_title(f'Distribution of {col}')
    
plt.tight_layout()
plt.show()

# Матрица корреляций
plt.figure(figsize=(12, 10))
correlation_matrix = df.select_dtypes(include=['float64', 'int64']).corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.show()

# Диаграмма рассеяния
sns.pairplot(df[numeric_cols[:5]])
plt.show()
```

### Задание 3: Предобработка данных

#### Обработка пропущенных значений
```python
# Проверка пропущенных значений
missing_values = df.isnull().sum()
print(missing_values[missing_values > 0])

# Заполнение пропусков средним значением
for col in df.columns:
    if df[col].isnull().sum() > 0:
        if df[col].dtype in ['float64', 'int64']:
        # Методы заполнения: 
        #     .mean(): Среднее значение
        #     .median(): Медиана
        #     .mode()[0]: Модальное значение
            value = df[col].median()
            df[col] = df[col].fillna(value) #df[col].method(value) # df.method({col: value}, inplace=True) ## df[col] = df.fillna(value)
        else:
        #.mode() возвращает Series (даже если мода только одна). [0] извлекает 
        #первое значение из этой Series, которое и является модальным значением.
        #Если бы вы использовали просто df[col].fillna(df[col].mode()), pandas 
        #попытался бы заполнить пропущенные значения целой Series, что привело 
        #бы к ошибке.
            df[col] = df[col].fillna(df[col].mode()[0])


# Проверка результата
print(df.isnull().sum().sum())
```


#### [[Кодирование категориальных признаков]]
```python
# Определение категориальных признаков
categorical_cols = df.select_dtypes(include=['object']).columns

# One-hot кодирование
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
print(df_encoded.shape)
print(df_encoded.columns)
```

#### [[Масштабирование числовых признаков]]
```python
from sklearn.preprocessing import StandardScaler

# Определение числовых признаков
numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns

# Создание объекта StandardScaler
scaler = StandardScaler()

# Масштабирование числовых признаков
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# Просмотр результата
print(df[numeric_cols].describe())
```

## Домашнее задание

### Задание 1: Разведочный анализ набора данных

Выполните полный разведочный анализ набора данных "Titanic" (или другого предложенного набора):

1. Загрузите данные и изучите их структуру
2. Проведите статистический анализ числовых и категориальных признаков
3. Визуализируйте распределения признаков и их взаимосвязи
4. Проанализируйте корреляции между признаками
5. Сформулируйте гипотезы о факторах, влияющих на целевую переменную
6. Подготовьте отчет с выводами и визуализациями

### Задание 2: Предобработка данных

Выполните предобработку набора данных для дальнейшего моделирования:

1. Обработайте пропущенные значения (выберите подходящую стратегию для каждого признака)
2. Обработайте выбросы в числовых признаках
3. Выполните кодирование категориальных признаков
4. Проведите масштабирование числовых признаков
5. Создайте новые признаки на основе существующих (feature engineering)
6. Разделите данные на обучающую и тестовую выборки
7. Сохраните предобработанные данные для дальнейшего использования

## Ресурсы и материалы

### Основные ресурсы
- [Документация scikit-learn](https://scikit-learn.org/stable/user_guide.html)
- [Документация Pandas](https://pandas.pydata.org/docs/)
- [Документация Matplotlib](https://matplotlib.org/stable/contents.html)
- [Документация Seaborn](https://seaborn.pydata.org/tutorial.html)

### Дополнительные материалы
- [Курс "Введение в машинное обучение" на Coursera](https://www.coursera.org/learn/machine-learning)
- [Книга "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow"](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
- [Статья "Exploratory Data Analysis for Feature Selection in Machine Learning"](https://towardsdatascience.com/exploratory-data-analysis-for-feature-selection-in-machine-learning-856e15a7ab3e)
- [Руководство по предобработке данных](https://scikit-learn.org/stable/modules/preprocessing.html)

### Наборы данных для практики
- [Titanic Dataset](https://www.kaggle.com/c/titanic/data)
- [Housing Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)
- [Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)

---

1. Количество билетов на класс:
	1. 1 - 216
	2. 2 - 184
	3. 3 - 491